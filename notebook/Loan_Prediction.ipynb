{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTML\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m\n\u001b[1;32m      8\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns',50)\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline\n",
    "\n",
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from xgboost import XGBClassifier,plot_importance\n",
    "\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    "table.dataframe td, table.dataframe th {\n",
    "    border: 1px  black solid !important;\n",
    "  color: black !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = train_df.columns[(train_df.dtypes=='float') | (train_df.dtypes=='int')]\n",
    "num_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = train_df.columns[train_df.dtypes=='object']\n",
    "cat_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking any null values exists in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_col= train_df.columns[train_df.isnull().any()]\n",
    "missing_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values imputation\n",
    "\n",
    "# train_df['Gender'] = train_df['Gender'].astype(str).fillna(train_df['Gender'].mode())\n",
    "# train_df['Married'] = train_df['Married'].astype(str).fillna(train_df['Married'].mode())\n",
    "# train_df['Dependents'] = train_df['Dependents'].astype(str).fillna(train_df['Dependents'])\n",
    "# train_df['Self_Employed'] = train_df['Self_Employed'].astype(str).fillna(train_df['Self_Employed'].mode())\n",
    "# train_df['LoanAmount'] = train_df['LoanAmount'].fillna(train_df['LoanAmount'].mean())\n",
    "# train_df['Loan_Amount_Term'] = train_df['Loan_Amount_Term'].fillna(train_df['Loan_Amount_Term'].mean())\n",
    "# train_df['Credit_History'] = train_df['Credit_History'].fillna(train_df['Credit_History'].mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_na(dataframe):\n",
    "    for c in missing_col:\n",
    "        if c in list(set(dataframe.columns[dataframe.dtypes=='object'])):\n",
    "            dataframe[c] = dataframe.loc[:,c].astype(str).fillna(dataframe.loc[:,c].mode())\n",
    "        else: \n",
    "            dataframe.loc[:,c] = dataframe.loc[:,c].fillna(dataframe.loc[:,c].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_na(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().sum().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_na(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Identity for presence of Outlier in datasets\n",
    "\n",
    "\"\"\"\n",
    "Z score is an important concept in statistics. Z score is also called standard score. This score helps to understand \n",
    "if a data value is greater or smaller than mean and how far away it is from the mean. More specifically, Z score tells \n",
    "how many standard deviations away a data point is from the mean.\n",
    "\n",
    "Z score = (x -mean) / std. deviation\n",
    "\n",
    "\n",
    "\n",
    "A normal distribution is shown below and it is estimated that\n",
    "68% of the data points lie between +/- 1 standard deviation.\n",
    "95% of the data points lie between +/- 2 standard deviation\n",
    "99.7% of the data points lie between +/- 3 standard deviation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename='z_score.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_df[num_col]:\n",
    "    outlier= []\n",
    "    col_mean = train_df[i].mean()\n",
    "    std_dev = np.std(train_df[i])\n",
    "    z = (train_df[i]-col_mean)/std_dev\n",
    "    if (z > col_mean).any():\n",
    "        outlier.append(i)        \n",
    "    print(\"mean of {} is {} and standard Deviation is {} \".format(i, col_mean,std_dev))\n",
    "    \n",
    "    print(\"outlier in {}\".format(i), outlier)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping loan_id from train_df and test_df\n",
    "train_df = train_df.drop('Loan_ID',axis=1)\n",
    "loan_ids = test_df['Loan_ID'].values\n",
    "test_df = test_df.drop('Loan_ID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_df[\"Loan_Status\"].value_counts()/train_df.shape[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = train_df[\"Loan_Status\"].value_counts().plot.pie(autopct='%.2f').set_title(\"Samples\")\n",
    "plt.savefig(\"../img/Samples.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_features_indices = np.where(train_df.dtypes != np.float)[0]\n",
    "\n",
    "# categorical_features_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.iloc[:,[0,1,2,3,4,10]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y = train_df.drop([\"Loan_Status\"], axis=1).values, train_df[\"Loan_Status\"].values\n",
    "X_test = test_df.values\n",
    "\n",
    "X_train.shape, Y.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold, scores = KFold(n_splits=5, shuffle=True,random_state=0) , list()\n",
    "for train,test in kfold.split(X_train):\n",
    "    x_train,x_test = X_train[train], X_train[test]\n",
    "    y_train, y_test = Y[train],Y[test]\n",
    "    \n",
    "    model = CatBoostClassifier(random_state=27,max_depth=4,task_type='CPU',devices='0:1',n_estimators=1000,verbose=True)\n",
    "    model.fit(x_train,y_train,cat_features = [0,1,2,3,4,10])\n",
    "    preds = model.predict(x_test)\n",
    "    score = f1_score(y_test,preds,average='weighted')\n",
    "    scores.append(score)\n",
    "    print(score)\n",
    "print(\"Average: \",sum(scores)/len(scores))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make final prediction using Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(random_state=27, task_type=\"GPU\", devices=\"0:1\", n_estimators=1000, max_depth=4, verbose=500)\n",
    "model.fit(X_train,Y,cat_features = [0,1,2,3,4,10] )\n",
    "preds1 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.Series(model.feature_importances_,index = train_df.drop('Loan_Status',axis=1).columns)\n",
    "feat_imp.nlargest(30).plot(kind='barh', figsize=(8,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing specific to LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_1 = train_df.copy()\n",
    "test_df_1 = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "train_df_1['Gender'] = le.fit_transform(train_df_1['Gender'])\n",
    "test_df_1['Gender'] = le.fit_transform(test_df_1['Gender'])\n",
    "\n",
    "train_df_1['Married'] = le.fit_transform(train_df_1['Married'])\n",
    "test_df_1['Married'] = le.fit_transform(test_df_1['Married'])\n",
    "\n",
    "\n",
    "train_df_1['Married'] = le.fit_transform(train_df_1['Married'])\n",
    "test_df_1['Married'] = le.fit_transform(test_df_1['Married'])\n",
    "\n",
    "train_df_1['Education'] = le.fit_transform(train_df_1['Education'])\n",
    "test_df_1['Education'] = le.fit_transform(test_df_1['Education'])\n",
    "\n",
    "train_df_1['Self_Employed'] = le.fit_transform(train_df_1['Self_Employed'])\n",
    "test_df_1['Self_Employed'] = le.fit_transform(test_df_1['Self_Employed'])\n",
    "\n",
    "train_df_1['Property_Area'] = le.fit_transform(train_df_1['Property_Area'])\n",
    "test_df_1['Property_Area'] = le.fit_transform(test_df_1['Property_Area'])\n",
    "\n",
    "\n",
    "\n",
    "train_df_1['Dependents']= le.fit_transform(train_df_1['Dependents'])\n",
    "test_df_1['Dependents']= le.fit_transform(test_df_1['Dependents'])\n",
    "\n",
    "\n",
    "train_df_1['Loan_Status']= le.fit_transform(train_df_1['Loan_Status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y = train_df_1.drop([\"Loan_Status\"], axis=1).values, train_df_1[\"Loan_Status\"].values\n",
    "X_test = test_df_1.values\n",
    "\n",
    "X_train.shape, Y.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 5,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3}  # the number of classes that exist in this datset\n",
    "num_round = 20  # the number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold, scores = KFold(n_splits=15, shuffle=True,random_state=0) , list()\n",
    "for train,test in kfold.split(X_train):\n",
    "    x_train,x_test = X_train[train], X_train[test]\n",
    "    y_train, y_test = Y[train],Y[test]\n",
    "    \n",
    "    model = XGBClassifier()\n",
    "    model.fit(x_train,y_train)\n",
    "    preds1 = model.predict(x_test)\n",
    "    print('Accuracy of Model is : ',accuracy_score(y_test,preds1))\n",
    "    score = f1_score(y_test,preds1,average='weighted')\n",
    "    scores.append(score)\n",
    "    print(score)\n",
    "print(\"Average: \",sum(scores)/len(scores))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a final Prediction using Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.5, gamma=0.4, learning_rate=0.1,\n",
    "       max_delta_step=0, max_depth=6, min_child_weight=7, missing=None,\n",
    "       n_estimators=1000, n_jobs=1, nthread=None,\n",
    "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "       subsample=1)\n",
    "model.fit(X_train,Y)\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('sample_submission_49d68Cx.csv')\n",
    "submission_df['Probability'] = preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del submission_df['Loan_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes =1 ; Loan = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['Loan_Status'] = ['Y' if x==1 else 'N' for x in submission_df['Probability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del submission_df['Probability']\n",
    "submission_df.to_csv('Xgb_Prediction.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "169f9dc8ead69990954b6aaf7dc15afc0ad199d265daee70554f7d47cc741d8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
